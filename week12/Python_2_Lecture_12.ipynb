{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WxqcDwBL4llb",
        "GhFY80KYMMGI",
        "kg90TL0oODbQ",
        "PEoDN6Wn3Rjx",
        "upB53OvdKBwl",
        "RlKfadD8DNXl",
        "iEIZLjBn7VZc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Продвинутый Python, лекция 12\n",
        "\n",
        "**Лектор:** Петров Тимур\n",
        "\n",
        "**Семинаристы:** Петров Тимур, Коган Александра, Бузаев Федор, Дешеулин Олег\n",
        "\n",
        "**Spoiler Alert:** в рамках курса нельзя изучить ни одну из тем от и до досконально (к сожалению, на это требуется больше времени, чем даже 3 часа в неделю). Но мы попробуем рассказать столько, сколько возможно :)"
      ],
      "metadata": {
        "id": "wAjy7jcIsEE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Threading"
      ],
      "metadata": {
        "id": "WxqcDwBL4llb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В первую очередь надо понять, что такое потоки (и в чем разница от процессов и корутин)\n",
        "\n",
        "Процесс - это инстанс программы, где у вас есть выполняемый код и собственные ресурсы памяти. У каждого процесса прямой доступ есть только к своим ресурсам. А поток (thread) - это разделение выполнения внутри процесса, где у всех потоков общий ресурс памяти (память процесса)\n",
        "\n",
        "Можно ли создавать бесконечное число тредов? Можно сколько угодно сделать (но надо ли?)"
      ],
      "metadata": {
        "id": "m0XHnpC544pw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Зачем нужны потоки? Ответ простой: таким образом мы можем выполнять одновременно несколько операций (это быстрее) + независимость (в отличие от корутин)\n",
        "\n",
        "Внутри Python за это отвечает библиотека [threading](https://docs.python.org/3/library/threading.html)"
      ],
      "metadata": {
        "id": "5Y4Bx_xKRk0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "На примере:"
      ],
      "metadata": {
        "id": "9iDV9zWcR6x9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import sys\n",
        "\n",
        "\n",
        "def thread_job(number):\n",
        "    print('Hello {}'.format(number)) # Выводим в stdout\n",
        "\n",
        "\n",
        "def run_threads(count):\n",
        "    threads = [\n",
        "        threading.Thread(target=thread_job, args=(i,)) # создаем по потоку, назначаем, что он должен делать, можем отдельно передавать аргументы\n",
        "        for i in range(0, count)\n",
        "    ]\n",
        "    for thread in threads:\n",
        "        thread.start()  # каждый поток должен быть запущен\n",
        "    for thread in threads:\n",
        "        thread.join()  # дожидаемся исполнения всех потоков (можем не дожидаться, дождаться надо, потому что может закончиться родительский тред)\n",
        "\n",
        "\n",
        "run_threads(4)\n",
        "print(\"finish\") #А тут уже что-то перемешалось (потому что поток вывода один)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0GFwX7rR_h3",
        "outputId": "ebf6ea64-3b3b-42f2-b0fa-b37df8154180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello 0\n",
            "Hello 1\n",
            "Hello 2Hello 3\n",
            "\n",
            "finish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mutex"
      ],
      "metadata": {
        "id": "E3JiWxs-59Cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте попробуем запустить вот такой код:"
      ],
      "metadata": {
        "id": "-83AxQqWXx-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "\n",
        "\n",
        "def thread_job():\n",
        "    global counter\n",
        "    old_counter = counter\n",
        "    time.sleep(random.randint(0, 1)) #засыпаем, чтобы вызвать проблему\n",
        "    counter = old_counter + 1\n",
        "    print('{} '.format(counter), end='')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "counter = 0\n",
        "threads = [threading.Thread(target=thread_job) for _ in range(4)]\n",
        "for thread in threads:\n",
        "    thread.start()\n",
        "for thread in threads:\n",
        "    thread.join()\n",
        "print(counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWRmUqRLX0ai",
        "outputId": "a7c93a3c-36cf-4616-82ae-fed698610ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 1 1 1 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Почему-то не получается 4. А как вы думаете, почему? А все потому что поток принимает текущее значение global переменной и добавляет 1 и возвращает результат. То есть таким образом они перезаписывают результат и все, мы получаем вот такую фигню. Такое состояние называется race condition\n",
        "\n",
        "Как решить подобную проблемы? Для этого есть Lock (более частое название - mutex). Что такое mutex? По существу, это замочек\n",
        "\n",
        "Когда поток забирает данные, мы говорим: \"Я забронил, вы не можете прикасаться к этим данным\". Когда же мы сделали все операции, мы освобождаем данные и говорим: ну все, можно пользоваться. На картинке:\n",
        "\n",
        "![](https://camo.githubusercontent.com/aff3fa583e71fd028e5850a0513f59805d1b758cd6acc03c63e2dc15d49e3ada/687474703a2f2f616e746b6f7277696e2e636f6d2f636f6e63757272656e63792f646961672d30363732383334613737333762623332333939306161626533626362356365362e706e67)\n",
        "\n"
      ],
      "metadata": {
        "id": "m7aNrj8rX35I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Внутри Threading есть имплементация мьютекса, который называется Lock() и с ним очень удобно работать через контекстный менеджер (заходим - блокируем, выходим - освобождаем)"
      ],
      "metadata": {
        "id": "qlzGGuVNINab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "\n",
        "\n",
        "def thread_job():\n",
        "    with lock: # Входим и блокируем ресурсы\n",
        "        global counter\n",
        "        old_counter = counter\n",
        "        time.sleep(random.randint(0, 1))\n",
        "        counter = old_counter + 1\n",
        "        print('{} '.format(counter), end='')\n",
        "        sys.stdout.flush()\n",
        "\n",
        "\n",
        "lock = threading.Lock()\n",
        "counter = 0\n",
        "threads = [threading.Thread(target=thread_job) for _ in range(8)]\n",
        "for thread in threads:\n",
        "    thread.start()\n",
        "for thread in threads:\n",
        "    thread.join()\n",
        "print(counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwYUKxJ3Ib79",
        "outputId": "abeb144f-3649-40d5-f4f5-4f2435952da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 2 3 4 5 6 7 8 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если хочется делать руками блокирование - разблокирование, то есть две функции:\n",
        "\n",
        "* acquire() - локаем\n",
        "\n",
        "* release() - делаем разлок\n",
        "\n",
        "Но обратите внимание - если не делать разлок, то все остальные треды будут в максимальном ожидании и ничего не случится (потому что ресурсы заблокированы другим тредом)"
      ],
      "metadata": {
        "id": "DJpU1NWRIp2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "\n",
        "\n",
        "def thread_job():\n",
        "    lock.acquire()\n",
        "    global counter\n",
        "    old_counter = counter\n",
        "    time.sleep(random.randint(0, 1))\n",
        "    counter = old_counter + 1\n",
        "    print('{} '.format(counter), end='')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "lock = threading.Lock()\n",
        "counter = 0\n",
        "threads = [threading.Thread(target=thread_job) for _ in range(8)]\n",
        "for thread in threads:\n",
        "    thread.start()\n",
        "for thread in threads:\n",
        "    thread.join() # будем ждать бесконечность\n",
        "print(counter)"
      ],
      "metadata": {
        "id": "XzSAvfi2JFjn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "a4b6cabb-d6c4-4459-a8cb-f19ae5e137ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-03222bf17235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# будем ждать бесконечность\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Но есть более лучшие вещи, например, очереди! (которая является thread-safe, то есть можно использовать спокойно для потоков)\n",
        "\n",
        "Идея: создаем очередь на вход и выход. Забираем тред из очереди на вход, кидаем его в очередь на выход\n"
      ],
      "metadata": {
        "id": "hSzNceFAdFJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import queue\n",
        "\n",
        "def adder(arr, part_id, thread_count, queue_out):\n",
        "    queue_out.put(sum(arr[i] for i in range(part_id, len(arr), thread_count)))\n",
        "\n",
        "\n",
        "def sum_threads(arr, thread_count):\n",
        "    queue_out = queue.Queue()\n",
        "    threads = [\n",
        "        threading.Thread(target= lambda i=i: adder(arr, i, thread_count, queue_out))\n",
        "        for i in range(thread_count)\n",
        "    ]\n",
        "    for thread in threads:\n",
        "        thread.start()\n",
        "    result = []\n",
        "    for thread in threads:\n",
        "        result.append(queue_out.get())\n",
        "        thread.join()\n",
        "    return sum(result)"
      ],
      "metadata": {
        "id": "Gps27RVzdP0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = [1 for _ in range(10**7)]"
      ],
      "metadata": {
        "id": "k2NHhUD_hkFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "sum(arr[i] for i in range(len(arr)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMIO2xLBhqRX",
        "outputId": "c04accd9-010a-4895-e602-68c6139b76e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 840 ms, sys: 0 ns, total: 840 ms\n",
            "Wall time: 844 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000000"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "sum_threads(arr, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5u53vD8hyMi",
        "outputId": "1da38c39-b755-4820-a136-a3d6ddb5e9ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 861 ms, sys: 8.54 ms, total: 870 ms\n",
            "Wall time: 989 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "А почему не в 4 раза улучшение?.."
      ],
      "metadata": {
        "id": "DSvdeN8xi6OX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GIL и проблемы"
      ],
      "metadata": {
        "id": "GhFY80KYMMGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://uwpce-pythoncert.github.io/SystemDevelopment/_images/gil.png)"
      ],
      "metadata": {
        "id": "NYNARtkWOIp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "На самом деле CPython - популярная реализация интерпретатора - имеет встроенный механизм, который обеспечивает выполнение ровно одного потока в любой момент времени. GIL облегчает реализацию интерпретатора, защищая объекты от одновременного доступа из нескольких потоков. По этой причине, создание несколько потоков не приведет к их одновременному исполнению на разных ядрах процессора. (и в этом проблема большая, Python не предназначен для этого)\n",
        "\n",
        "То есть распараллелить подсчеты в помощью Python невозможно... можно задать логичный вопрос, а нафига оно тогда? Ответ простой: просто не для такой работы он нужен)"
      ],
      "metadata": {
        "id": "F4VQnYVWPKZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "urls = ['http://wiki.cs.hse.ru/Заглавная_страница', 'https://ya.ru/', 'https://docs.python.org/3/library/multiprocessing.html',\n",
        "        'https://colab.research.google.com/', 'https://www.youtube.com/', 'https://mail.ru/']"
      ],
      "metadata": {
        "id": "y0nk8BzDj2mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_url(url):\n",
        "    return requests.get(url).text"
      ],
      "metadata": {
        "id": "ZhtwuK5MkVKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for url in urls:\n",
        "    read_url(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggB5o3JHlEwh",
        "outputId": "cf06ec93-887e-4972-dffe-c31e76faeb30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 137 ms, sys: 19.2 ms, total: 156 ms\n",
            "Wall time: 4.87 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "threads = [\n",
        "    threading.Thread(target=lambda url=url: read_url(url))\n",
        "    for url in urls\n",
        "]\n",
        "for thread in threads:\n",
        "    thread.start()\n",
        "for thread in threads:\n",
        "    thread.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OvE1-3elKd9",
        "outputId": "aac7c987-f507-43a7-fb13-d53201e39840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 128 ms, sys: 16.1 ms, total: 144 ms\n",
            "Wall time: 1.56 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "То есть параллелим мы запросы, которые требуют \"ничего не ожидания\" (а в таких случаях GIL отпускается)\n",
        "\n",
        "В каких еще случаях GIL отпускается?\n",
        "\n",
        "* Задачи, связанные с вводом-выводом (чтение файла)\n",
        "\n",
        "* Операции с базами данных\n",
        "\n",
        "* HTTP-запросы"
      ],
      "metadata": {
        "id": "QoDmyKihlsJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiprocessing"
      ],
      "metadata": {
        "id": "kg90TL0oODbQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Библиотека [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) позволяет организовать параллелизм вычислений за счет создания подпроцессов. Так как каждый процесс выполняется независимо от других, этот метод параллелизма позволяет избежать проблем с GIL.\n",
        "\n",
        "В чем разница? В данном случае внутри процесса создаем подпроцессы (дробим процесс, то есть и память и все остальное). И в этом смысле мы реально делим на ядра (каждое ядро выполняет свою часть). Разбивая процесс на подпроцессы мы создаем отдельно интерпретаторы для каждой части, которые выполняются независимо (такая реальная параллельность), но при этом они могут друг с другом перекидываться данными\n",
        "\n",
        "Число процессов ограничивается число ядер. Как узнать число ядер:"
      ],
      "metadata": {
        "id": "iw2qYtUg6Afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing as mp\n",
        "\n",
        "print(mp.cpu_count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSYDWRTYVsst",
        "outputId": "e7f3d121-6dbc-4d9a-f566-ed773bc36c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте создавать различные процессы!"
      ],
      "metadata": {
        "id": "1UZnJH1JWIYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "\n",
        "def f():\n",
        "    result.append(\"Hi\")\n",
        "\n",
        "processes = [mp.Process(target=f) for _ in range(2)]\n",
        "for p in processes:\n",
        "    p.start()\n",
        "for p in processes:\n",
        "    p.join()\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADH-AMvSWVdk",
        "outputId": "f9078030-97f9-429e-8abd-0fefb03a65b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "А чего это ничего не получилось? Потому что каждый процесс - это процесс (соответственно, своя память, свои локальные переменные, обмена никакого нет, получаем пустоту)\n",
        "\n",
        "Как бы этого избежать? Для этого есть такая штука как Pool() - это связанный набор воркеров, которые обмениваются друг с другом данными и полученными результатами:"
      ],
      "metadata": {
        "id": "JgZmcgVyuClP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "    return x ** 2\n",
        "\n",
        "with mp.Pool() as pool:\n",
        "    result = pool.map(f, range(10)) # аналог функции map, только для процессов\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfVvYCBnuHaX",
        "outputId": "4a3b4c2a-bff1-451a-a8c2-15ed10960655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = [1 for _ in range(10**7)]"
      ],
      "metadata": {
        "id": "JzlbBGoTueaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "sum(arr[i] for i in range(len(arr)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYhf4yoiuukC",
        "outputId": "b9365007-c9e2-49d3-b160-eb7af4144cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 903 ms, sys: 0 ns, total: 903 ms\n",
            "Wall time: 913 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000000"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size = len(arr)\n",
        "process_count = mp.cpu_count()\n",
        "part_size = size // process_count\n",
        "array_parts = [\n",
        "    arr[i * part_size: (i + 1) * part_size]\n",
        "    for i in range(process_count)\n",
        "]"
      ],
      "metadata": {
        "id": "w6R2nOajuvT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with mp.Pool(process_count) as pool:\n",
        "    pool.map(sum, array_parts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwRHDdSIvBqX",
        "outputId": "bc13bd00-63e0-45ce-af02-f67bf7fdcb9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 321 ms, sys: 284 ms, total: 605 ms\n",
            "Wall time: 1.95 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получили не сильно больше, а почему? А потому что обмен данными между подпроцессами - удовольствие дорогое (как можно видеть по sys)\n",
        "\n",
        "Зачем это все тогда нужно? Это нужно, если вы хотите запустить несколько процессов, которые друг с другом не связаны, например, и таким образом вам не надо передавать много данных (а задачи сами по себе сложные)"
      ],
      "metadata": {
        "id": "dl2fuj4QvYFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Асинхронность"
      ],
      "metadata": {
        "id": "PEoDN6Wn3Rjx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Что такое асинхронность? Представим себе программу, которая запрашивает данные на каком-либо сервере. Отправляется запрос... ждем ... ждем ... и получаем ответ.\n",
        "\n",
        "Что происходит в момент ожидания? Ничего, мы просто ждем результата. А вообще было бы классно не тратить время попусту (как и ресурсы), а делать что-то еще (как будто наше ожидание происходит на фоне). В этом и суть асинхронности!\n",
        "\n",
        "У нас есть несколько функций, которые мы вызываем, но не ожидаем результат прямо сейчас. Внутри асинхронного программирования - идея конкурентности (concurrency) — две или более задачи могут запускаться, выполняться и завершаться в перекрывающиеся периоды времени.\n",
        "\n",
        "Для этого в Python есть библиотека [asyncio](https://docs.python.org/3/library/asyncio.html), которая основана на корутинах. Корутины - это некоторая функция, которая может начинаться, приостанавливаться и завершаться в произвольный момент времени.\n",
        "\n",
        "Давайте на примере:"
      ],
      "metadata": {
        "id": "pCqLIv3CtWt0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eu63f4cgr7rw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fe963e9-230b-417b-dc5a-8dfe926b1348"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<coroutine object print_sum at 0x7fb19d0708c0>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "import asyncio\n",
        "\n",
        "async def compute(a, b):\n",
        "    print('Compute...')\n",
        "    await asyncio.sleep(1.0)\n",
        "    return a + b\n",
        "\n",
        "async def print_sum(a, b):\n",
        "    result = await compute(a, b)\n",
        "    print('{} + {} = {}'.format(a, b, result))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "async def compute(a, b):\n",
        "    print('Compute...')\n",
        "    await asyncio.sleep(1.0)\n",
        "    return a + b\n",
        "\n",
        "async def main():\n",
        "    a, b = 1, 2\n",
        "    result = await compute(a, b)\n",
        "    print('{} + {} = {}'.format(a, b, result))\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9gEJjzqCToK",
        "outputId": "65c689bd-4f3e-49ee-b056-15f457710ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compute...\n",
            "1 + 2 = 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Что здесь происходит?\n",
        "\n",
        "Мы создали две корутины, compute и print_sum (указывается с помощью слова async)\n",
        "\n",
        "Далее мы запустили наше выполнение с помощью так называемого event_loop, который берет нашу функцию, и запускает ее. В свою очередь, наша корутина compute запускается и находится в режиме ожидания, пока не выполнится compute() (это делается с помощью слова await). После ожидания в секунду, compute выводит ответ, который передается к print_sum (напоминаю, все это время print_sum выполняется) и далее выводит ответ\n",
        "\n",
        "Общая схема выглядит вот так:\n",
        "\n",
        "![](https://camo.githubusercontent.com/de86a2c33affd5101ddc77b69a274823e643bda2/687474703a2f2f6e746f6c6c2e6f72672f7374617469632f696d616765732f74756c69705f636f726f2e706e67)"
      ],
      "metadata": {
        "id": "Tu6Iw_QGy8tV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Понятное дело, что сейчас собрали такой игрушечный пример (какой сейчас был смсл так сделать). Но таким образом можно запустить выполнение и ждать результата, например, от нескольких функций etc. Давайте на вот таком примере:"
      ],
      "metadata": {
        "id": "Aiatj43I0ggu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "async def factorial(name, number):\n",
        "    f = 1\n",
        "    for i in range(2, number + 1):\n",
        "        print(f\"Task {name}: Compute factorial({i})...\")\n",
        "        await asyncio.sleep(1)\n",
        "        f *= i\n",
        "    print(f\"Task {name}: factorial({number}) = {f}\")\n",
        "    return f\n",
        "\n",
        "res = await asyncio.gather(\n",
        "    factorial(\"A\", 2),\n",
        "    factorial(\"B\", 3),\n",
        "    factorial(\"C\", 4),\n",
        "    return_exceptions= True # как обрабатывать ошибки, если что-то упадет\n",
        ")\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "5f4c8kYd1gCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c88adf-9110-4530-a672-b2ac1bfeeb5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task A: Compute factorial(2)...\n",
            "Task B: Compute factorial(2)...\n",
            "Task C: Compute factorial(2)...\n",
            "Task A: factorial(2) = 2\n",
            "Task B: Compute factorial(3)...\n",
            "Task C: Compute factorial(3)...\n",
            "Task B: factorial(3) = 6\n",
            "Task C: Compute factorial(4)...\n",
            "Task C: factorial(4) = 24\n",
            "[2, 6, 24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Что у нас происходит здесь и что добавилось?\n",
        "\n",
        "* gather - запусти все, что мы перечислили, асихнронно\n",
        "\n",
        "Что мы видим по выводу?\n",
        "\n",
        "У нас есть таска A, B, C. В линейной логике мы бы вначале посчитали A, потом B, потом C (и все время ожидания сложилось бы). Как это здесь работает?\n",
        "\n",
        "Идем в задачу A, что-то сделали, уходим в режим ожидания. Пока ожидаем, можно взять и что-то сделать в таске B, уходим, можем сделать что-то в таске С. Дождались внутри A, делаем ее и так далее. Таким образом, мы делаем 3 таски в одно время"
      ],
      "metadata": {
        "id": "N7iwjnmM13vY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://pythonru.com/wp-content/uploads/2021/05/ispolzovanii-asinhronnosti.png)"
      ],
      "metadata": {
        "id": "RMF52HUSJjsF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ограничение ожидания"
      ],
      "metadata": {
        "id": "CK2kOCcu3QuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отлично, можем делать что-то асинхронно, но что, если у нас один из вызовов затупил настолько, что мы не хотим ждать и пойти делать дальше что-то без него (скажем, какой-то сервер упал, ответа от него мы не дождемся)?\n",
        "\n",
        "Для этого есть timeout - ограничение на время ответа"
      ],
      "metadata": {
        "id": "C-t1HE3S3Vgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "async def eternity():\n",
        "    await asyncio.sleep(3600)\n",
        "    print('yay!')\n",
        "\n",
        "\n",
        "# Wait for at most 1 second\n",
        "try:\n",
        "    await asyncio.wait_for(eternity(), timeout=1.0) # Отдельная функция wait_for, то есть ждем функцию, но ограничиваем по времени\n",
        "except asyncio.TimeoutError: # если выплюнул ошибку ожидания, то делаем то или иное\n",
        "    print('timeout!')\n"
      ],
      "metadata": {
        "id": "OfyRqyIX3s9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb103748-a217-4078-ae5e-d307e817df84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "timeout!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Что происходит на уровне корутины? Он ловит ошибку, убивается и закрывается. Но внутри той же самой корутины можно сделать что-то еще с этой ошибкой (и это нормально)"
      ],
      "metadata": {
        "id": "5uI_S1UZ_tSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "async def eternity():\n",
        "    try:\n",
        "        await asyncio.sleep(3600)\n",
        "        print('yay!')\n",
        "    except asyncio.CancelledError:\n",
        "        print(\"closed\")\n",
        "        await asyncio.sleep(5)\n",
        "\n",
        "# Wait for at most 1 second\n",
        "try:\n",
        "    await asyncio.wait_for(eternity(), timeout=1.0) # Отдельная функция wait_for, то есть ждем функцию, но ограничиваем по времени\n",
        "except asyncio.TimeoutError: # если выплюнул ошибку ожидания, то делаем то или иное\n",
        "    print('timeout!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-qozhb3_s_z",
        "outputId": "83d08600-c213-4e48-b9c5-db70e9b6bbb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "closed\n",
            "timeout!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "А ежели мы хотим сделать так, чтобы она все-таки доработала, но скинула ошибку того, что она работает долго? На этот случай есть shield (защита от отмены таска):"
      ],
      "metadata": {
        "id": "XmasZweoBKnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "async def eternity():\n",
        "    await asyncio.sleep(5)\n",
        "    print('yay!')\n",
        "\n",
        "# Wait for at most 1 second\n",
        "try:\n",
        "    await asyncio.wait_for(asyncio.shield(eternity()), timeout=1.0) # Отдельная функция wait_for, то есть ждем функцию, но ограничиваем по времени\n",
        "except asyncio.TimeoutError: # если выплюнул ошибку ожидания, то делаем то или иное\n",
        "    print('timeout!')\n",
        "    await asyncio.sleep(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XU5Vov0BVES",
        "outputId": "1f73df1c-3441-4d12-e8b0-4375fd4efed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "timeout!\n",
            "yay!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Таски"
      ],
      "metadata": {
        "id": "upB53OvdKBwl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "У нас есть ожидание, есть запуски и так далее. А нельзя это как-то обернуть в сущность типа задачи, которую можно вызвать позже сразу как результат? Можно! Для этого есть объект Task, который создается с помощью функции create_task() (и отсчет начинается уже в момент создания таски):"
      ],
      "metadata": {
        "id": "ANp0ZwTPKDh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import time\n",
        "\n",
        "async def say(word, delay):\n",
        "    print(\"heh\" + word)\n",
        "    await asyncio.sleep(delay)\n",
        "    print(word)\n",
        "\n",
        "t_1 = asyncio.create_task(say(\"Hi_1\", 2))\n",
        "t_2 = asyncio.create_task(say(\"Hi_2\", 1))\n",
        "\n",
        "print(time.strftime(\"%X\"))\n",
        "\n",
        "await t_1\n",
        "await t_2\n",
        "\n",
        "print(time.strftime(\"%X\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOufky448bk7",
        "outputId": "416948b7-cc50-4b71-95e8-89a5c1e374e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16:41:22\n",
            "hehHi_1\n",
            "hehHi_2\n",
            "Hi_2\n",
            "Hi_1\n",
            "16:41:24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Забираем результаты как придут"
      ],
      "metadata": {
        "id": "RlKfadD8DNXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Хорошо, у нас есть несколько корутин, умеем запускать с помощью gather, а как сразу забирать результаты, не ожидая окончания каждого из них? На это есть as_completed:"
      ],
      "metadata": {
        "id": "COWMCrJ6DRbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def fact(number):\n",
        "    res = 1\n",
        "    for i in range(2, number + 1):\n",
        "        await asyncio.sleep(1)\n",
        "        res *= i\n",
        "    return number, res\n",
        "\n",
        "for i, future in enumerate(asyncio.as_completed([fact(4), fact(3), fact(2)])):\n",
        "    number, result = await future\n",
        "    print(f\"Factorial({number}) = {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JijfXtPbDgWF",
        "outputId": "58667af4-540c-4873-b8cd-354af1b52972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial(2) = 2\n",
            "Factorial(3) = 6\n",
            "Factorial(4) = 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## А что и когда вообще использовать?"
      ],
      "metadata": {
        "id": "La16vfyqUHiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Сложные задачи, мало коннектятся друг с другом, есть ресурсы - multiprocessing\n",
        "\n",
        "* Остальное - комбинация threading и asyncio"
      ],
      "metadata": {
        "id": "1pflmmMYFMYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Попугай дня"
      ],
      "metadata": {
        "id": "iEIZLjBn7VZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://do-slez.com/uploads/posts/2020-02/1582813051_pesquets-dracula-parrots-birds-new-guinea-1-5e55392f17e1e__700.jpg)"
      ],
      "metadata": {
        "id": "drlXbB4w_RnG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сегодня у нас очень красивый орлиный попугай (орлиный за счет его клюва) и сходит в семейство щетиноголовых попугаев (видите какая щетина у него прям)"
      ],
      "metadata": {
        "id": "6z3hTgu9_Xk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://img.theepochtimes.com/assets/uploads/2020/05/14/Dracula-Parrot-i.jpg)"
      ],
      "metadata": {
        "id": "BgnEsrFe_mGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Исторически живет в Новой Гвинее и его очень редко можно встретить в зоопарках из-за очень прихотливого питания (им обязательно нужны тропические фрукты для ферментации) и требований к содержанию (температура, влажность)\n",
        "\n",
        "Еще один, к сожалению, вымирающий вид, потому что на них охотятся индейцы за их красные перья (хоть и достаточно распространен в авикультуре, но выращивать его очень сложно)."
      ],
      "metadata": {
        "id": "GW5PDacP_yNY"
      }
    }
  ]
}